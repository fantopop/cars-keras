{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Исходный нотубук с заданием и ссылка на данные: https://github.com/ton4eg/coursera_pa*  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Programming Assignment - Анализ Изображений\n",
    "В этот ноутбуке будет выполнено задание второй недели 5-го курса специализации \"Машинное обучение и анализ данных\" с использованием библиотеки Keras. Перед запуском ноутбука убедитесь, что в папке с ноутбуком лежат файлы для обучение и теста в папках `train` и `test`, а также файлы с метками картинок и имена классов: `results.txt` и `class_names.txt`. Подробнее про предобученные модели в Keras тут: https://keras.io/applications/  \n",
    "> **Обратите внимание!** Полученные ответы отличаются от ответов, полученных мной используя только tensorflow, как предлагается в задании. Этот ноутбук - только пример того, как можно выполнить это же задание, но с использованием других инструментов и проанализировать результаты, взглянув на картинки.\n",
    "\n",
    "### Установка Keras\n",
    "Установаить Keras можно с помощью комманды:  \n",
    "\n",
    "`conda install -c conda-forge keras`  \n",
    "\n",
    "Ссылка на иснтрукции по установке: https://keras.io/#installation  \n",
    "\n",
    "### Установка ipywidgets\n",
    "Чтобы в этом ноутбуке работал выбор картинок для анализа результатов нужно установить и включить ipywidgets:\n",
    "\n",
    "1. `conda install -c conda-forge ipywidgets`\n",
    "2. `jupyter nbextension enable --py widgetsnbextension`\n",
    "\n",
    "Больше информации тут: https://ipywidgets.readthedocs.io/en/stable/user_install.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input, decode_predictions\n",
    "from keras.models import Model\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from ipywidgets import interact\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess image from path.\n",
    "def load_preprocess(img_path):\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load correct labels for the dataset as dict.\n",
    "def load_labels(fname):\n",
    "    labels = {}\n",
    "    with open(fname) as f:\n",
    "        for line in f:\n",
    "            fname, class_id = line.strip().split()\n",
    "            labels[fname] = class_id\n",
    "    return labels\n",
    "\n",
    "\n",
    "# Loas class names for labels as dict.\n",
    "def load_class_names(fname):\n",
    "    i = 1\n",
    "    class_names = {}\n",
    "    with open(fname) as f:\n",
    "        for car_name in f:\n",
    "            class_names[i] = car_name\n",
    "            i += 1\n",
    "    return class_names\n",
    "\n",
    "\n",
    "# Get list of input files from folder and list of labels for these files.\n",
    "def get_inputs(folder, labels):\n",
    "    X = glob.glob(folder + '/*.jpg')\n",
    "    Y = [labels[os.path.basename(x)] for x in X]\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get lists of train and test files and labels\n",
    "labels = load_labels('results.txt')\n",
    "train, labels_train = get_inputs('train', labels)\n",
    "test, labels_test = get_inputs('test', labels)\n",
    "\n",
    "# Get dict of classes descriptions.\n",
    "class_names = load_class_names('class_names.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base VGG16 model with all layers\n",
    "base_model = VGG16(weights='imagenet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1.\n",
    "\n",
    "Для начала нужно запустить готовую модель `vgg16`, предобученную на `imagenet`. Модель обучена с помощью `caffe` и сконвертирована в формат `tensorflow` - `vgg16_weights.npz`. Скрипт, иллюстрирующий применение этой модели к изображению, возвращает топ-5 классов из `imagenet` и уверенность в этих классах.\n",
    "\n",
    "**Задание:** Загрузите уверенность для первого класса для изображения `train/00002.jpg` с точностью до 1 знака после запятой в файл с ответом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact(img_path=train)\n",
    "def classify_img(img_path):\n",
    "    # Load and preprocess image.\n",
    "    x = load_preprocess(img_path)\n",
    "    \n",
    "    # Get label and class name.\n",
    "    y = labels_train[train.index(img_path)]\n",
    "    y_name = class_names[int(y)]\n",
    "    \n",
    "    # Get model predictions for the image.\n",
    "    preds = base_model.predict(x)\n",
    "    \n",
    "    # Decode the results into a list of tuples (class, description, probability).\n",
    "    preds_decoded = decode_predictions(preds, top=5)[0]\n",
    "    \n",
    "    print('Predicted:')\n",
    "    for _, label, p in preds_decoded:\n",
    "        print('{:<20}{:.4f}'.format(label, p))\n",
    "        \n",
    "    plt.imshow(image.load_img(img_path))\n",
    "    plt.title(y + ': ' + y_name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2\n",
    "\n",
    "Научитесь извлекать `fc2` слой. Возьмите за основу код `process_image`, и модифицируйте, чтобы вместо последнего слоя извлекались выходы `fc2`.\n",
    "\n",
    "**Задание:** Посчитайте `fc2` для картинки `train/00002.jpg`.  Запишите первые 20 компонент."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model with output of 'fc2' layer of the base model.\n",
    "model = Model(inputs=base_model.input, outputs=base_model.get_layer('fc2').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess image.\n",
    "x = load_preprocess('train/00002.jpg')\n",
    "\n",
    "img_fc2_out = model.predict(x)\n",
    "print(img_fc2_out[:, :20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 3\n",
    "\n",
    "Теперь необходимо дообучить классификатор на нашей базе. В качестве бейзлайна предлагается воспользоваться классификатором `svm` из пакета `sklearn`.\n",
    "\n",
    "- Модифицировать функцию `get_features` и добавить возможность вычислять `fc2`. (Аналогично второму заданию).\n",
    "- Применить `get_feautures`, чтобы получить `X_test` и `Y_test`.\n",
    "- Воспользоваться классификатором `SVC` с `random_state=0`.\n",
    "\n",
    "> **Важно!** Если вам не удалось поставить `tensorflow`, то необходимо вместо использования функции `get_features`, загрузить предпосчитанные `X`, `Y`, `X_test`, `Y_test` из архива: https://yadi.sk/d/RzMOK8Fjvs6Ln и воспользоваться функцией `np.load` для их загрузки, а после этого два последних пункта.\n",
    "\n",
    "**Задание:** Сколько правильных ответов получается на валидационной выборке из папки `test`? Запишите в файл."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get outputs of the model for list of images.\n",
    "def get_features(img_paths, model):\n",
    "    X = np.zeros((len(img_paths), 4096))\n",
    "    for i, img_path in enumerate(img_paths):\n",
    "        print(img_path)\n",
    "        x = load_preprocess(img_path)\n",
    "        X[i, :] = model.predict(x).squeeze()\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = get_features(train, model)\n",
    "X_test = get_features(test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf = SVC(random_state=0)\n",
    "\n",
    "clf.fit(X, labels_train)\n",
    "labels_predicted = clf.predict(X_test)\n",
    "print('Count of correct predictions: %d of %d' % (np.sum(labels_predicted == labels_test), X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact(img_path=test)\n",
    "def classify_car(img_path):\n",
    "    # Index of the current image in test, labels_test and labels_predicted arrays.\n",
    "    i = test.index(img_path)\n",
    "    \n",
    "    # Get true car model\n",
    "    y_true = labels_test[i]\n",
    "    y_name_true = class_names[int(y_true)]\n",
    "    \n",
    "    # Get predicted car model\n",
    "    y_pred = labels_predicted[i]\n",
    "    y_name_pred = class_names[int(y_pred)]\n",
    "    \n",
    "    print('{:<20}{}'.format('True', y_name_true))\n",
    "    print('{:<20}{}'.format('Predicted', y_name_pred))\n",
    "        \n",
    "    plt.imshow(image.load_img(img_path))\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
